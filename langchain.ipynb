{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c88f57bc-9d82-4922-8964-60e6680d55d0",
   "metadata": {},
   "source": [
    "## Load Model from HugginFace(Local) to langchain\n",
    "\n",
    "[link to hugginface](https://huggingface.co/docs/hub/index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93e0c45e-cd09-4ddb-947c-9513bd9eb21a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain import HuggingFacePipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b689d738-75e6-4eb9-a15f-2393d174bf43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MAX_LEN=1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0dfd8bd-25f8-44d1-8ae2-2a21ed62c176",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model_args = {\n",
    "#     'model_id':\"stabilityai/stablelm-tuned-alpha-3b\",\n",
    "#     'task':'text-generation'\n",
    "# }\n",
    "model_args = {\n",
    "    # 'model_id':\"declare-lab/flan-alpaca-gpt4-xl\",\n",
    "    'model_id':'declare-lab/flan-alpaca-large',\n",
    "    'task':\"text2text-generation\"\n",
    "}\n",
    "# model_args = {\n",
    "#     'model_id':'google/flan-t5-xl',\n",
    "#     'task':'text2text-generation'\n",
    "# }\n",
    "# model_args = {\n",
    "#     'model_id':'lmsys/fastchat-t5-3b-v1.0',\n",
    "#     'task':'text2text-generation'\n",
    "# }\n",
    "# model_args = {\n",
    "#     'model_id':'BlinkDL/rwkv-4-raven',\n",
    "#     'task':'text2text\n",
    "# }\n",
    "# model_args = {\n",
    "#     'model_id':'TheBloke/stable-vicuna-13B-HF',\n",
    "#     'task':'text-generation'\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2524c1cf-7c1e-4144-8cef-88e284458419",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm = HuggingFacePipeline.from_model_id(\n",
    "    **model_args,\n",
    "    model_kwargs={\"temperature\":0, \"max_length\":MAX_LEN},\n",
    "    device=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d69b42-90ba-4b1b-956a-fd2ff0fb99cb",
   "metadata": {},
   "source": [
    "## Import model to Langchain with prompts, define the chain\n",
    "\n",
    "further explainations of the chain could be found [here](https://python.langchain.com/en/latest/modules/chains/getting_started.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2169026-3a7a-4677-a557-6306ffc57451",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate, LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c475a3-addf-4559-8a45-31cbd5a7670e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "template = \"\"\"Question: {question}\n",
    "\n",
    "Answer: Let's think step by step.\"\"\"\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"question\"])\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
    "\n",
    "question = \"Who won the FIFA World Cup in the year 1994? \"\n",
    "\n",
    "# call llm_chain with only reply (meaning the reply is in the form of a string)\n",
    "print(llm_chain.run(question))\n",
    "\n",
    "# call llm_chain (return will be a dictionary)\n",
    "# llm_chain(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7257d27-c521-4397-a25f-e5901ceb39e9",
   "metadata": {},
   "source": [
    "##ã€€Add memory to Chain\n",
    "\n",
    "* step 1: Set a prompt template to require memory for each input\n",
    "* step 2: Declare a memory\n",
    "* step 3: Add memory to Chain\n",
    "\n",
    "note that the `verbose=True` is used for debugging and checking what the model is outputing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e64329-e7e3-4e9a-9998-eb120da3cc8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory, ConversationBufferWindowMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043b144b-54e4-42ae-bb12-f47ba8da3438",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chatbot_template = \"\"\"\n",
    "\n",
    "{chat_history}\n",
    "Human: {human_input}\n",
    "Chatbot:\"\"\"\n",
    "\n",
    "chatbot_prompt = PromptTemplate(\n",
    "    input_variables=[\"chat_history\", \"human_input\"], \n",
    "    template=chatbot_template\n",
    ")\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc1949d-407f-4575-817c-53094c001750",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# conversation = ConversationChain(\n",
    "#     llm=chat,\n",
    "#     memory=ConversationBufferMemory()\n",
    "# )\n",
    "\n",
    "conversation = LLMChain(\n",
    "    prompt=chatbot_prompt,\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ed20dc-0ef1-4b15-8dd4-d02d99ba520e",
   "metadata": {},
   "source": [
    "## Chatbot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a22c073-d053-4040-bc0e-3e43ada29f8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "template = \"\"\"You are a musician that is very good at the guitar. You also do not have many friends and will be frightened to talk to a stranger. This is a conversation between you and a person you just met. Do not be rude and also it is ok for you to not know the answer of the question.\n",
    "You normally repeat the same thing twice if you are not familiar to the person you are talking to.\n",
    "\n",
    "{history}\n",
    "Human: {human_input}\n",
    "Assistant:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"history\", \"human_input\"], \n",
    "    template=template\n",
    ")\n",
    "\n",
    "\n",
    "chatgpt_chain = LLMChain(\n",
    "    llm=llm, \n",
    "    prompt=prompt, \n",
    "    verbose=True, \n",
    "    memory=ConversationBufferWindowMemory(k=3),\n",
    ")\n",
    "\n",
    "output = chatgpt_chain.predict(human_input=\"Hi, nice to meet you. Can you introduce yourself?\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813433b4-b4f3-49b9-9c2b-49d158062e77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "while True:\n",
    "    human_input=input()\n",
    "    if human_input=='break':\n",
    "        break\n",
    "    output = chatgpt_chain.predict(human_input=human_input)\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c3022a-59db-40d5-b022-d24337350397",
   "metadata": {},
   "source": [
    "## Ideas for LangChain\n",
    "\n",
    "1. GAN with langchain\n",
    "2. Khanmigo\n",
    "3. Agents for playing games (try to represent the game state in prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7ebce9-982c-459e-b9de-e7ce0eb10744",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "template = \"\"\"Your task is to be a brainstorming partner and provide creative ideas and suggestions for a given topic or problem.\\\n",
    "Your response should include original, unique, and relevant ideas that could help solve the problem\\\n",
    "or further explore the topic in an interesting way.\\\n",
    "Please note that your response should also take into account any specific requirements or constraints of the task.\n",
    "\n",
    "Use the following format:\n",
    "\n",
    "Question: the input question you must answer\n",
    "Thought: you should always think about what to do\n",
    "\n",
    "Begin! Remember to speak as in an interesting way.\n",
    "\n",
    "Human: {human_input}\n",
    "Assistant:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bac665d-9c63-49e5-995b-9fdd8bc9e648",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "template = \"\"\"Answer the following questions as best you can using the following format:\n",
    "\n",
    "Format:\n",
    "\n",
    "Question: the question you need to answer.\n",
    "Thought: one idea that can be done to answer the question.\n",
    "Action: Which of the ideas is best to solve the question\n",
    "Observation: what is predicted to happen after taking the action.\n",
    "Final Answer: the final answer to the original input question\n",
    "\n",
    "Begin! Remember to speak as creative as possible when giving your final answer.\n",
    "\n",
    "Question: {human_input}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f9ab55-e1f4-4a24-a0a0-9f74fb708d5f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"human_input\"], \n",
    "    template=template\n",
    ")\n",
    "\n",
    "\n",
    "chatgpt_chain = LLMChain(\n",
    "    llm=llm, \n",
    "    prompt=prompt, \n",
    "    verbose=True, \n",
    "    # memory=ConversationBufferWindowMemory(k=3),\n",
    ")\n",
    "\n",
    "output = chatgpt_chain.predict(human_input=\"please write a function of bubble sort in python\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eea6728-fad1-410a-916f-571a4fdf3168",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output = chatgpt_chain.predict(human_input=\"when did shakespear die\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42226721-a268-4430-b286-eb44b906052a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.agents import Tool, AgentExecutor, LLMSingleActionAgent, AgentOutputParser, load_tools\n",
    "from langchain.prompts import StringPromptTemplate\n",
    "from langchain import LLMChain, SerpAPIWrapper, OpenAI\n",
    "from typing import List, Union\n",
    "from langchain.schema import AgentAction, AgentFinish\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d4d92043-0ef7-41fe-9e81-c9012587b207",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"SERPAPI_API_KEY\"] = \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb64f44-e88a-4b6a-aed1-8ec735e6aae9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm_openai = OpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66a293e-144e-4cea-823d-a533ee848743",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm_openai(\"aifejaofjao\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed655250-2974-46f1-805a-4efa10b71ac2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "search = SerpAPIWrapper()\n",
    "tools = [\n",
    "    Tool(\n",
    "        name = \"Search\",\n",
    "        func=search.run,\n",
    "        description=\"useful for when you need to answer questions about current events\"\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2b08b4-9d50-4581-847a-58cd75365658",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set up the base template\n",
    "template = \"\"\"Answer the following questions as best you can, but speaking as a pirate might speak. You have access to the following tools:\n",
    "\n",
    "{tools}\n",
    "\n",
    "Use the following format:\n",
    "\n",
    "Question: the input question you must answer\n",
    "Thought: you should always think about what to do\n",
    "Action: the action to take, should be one of [{tool_names}]\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the original input question\n",
    "\n",
    "Begin! Remember to speak as a pirate when giving your final answer. Use lots of \"Arg\"s\n",
    "\n",
    "Question: {input}\n",
    "{agent_scratchpad}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6dcb4c-6f40-4ebd-bc31-c0e86fa6c4af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set up a prompt template\n",
    "class CustomPromptTemplate(StringPromptTemplate):\n",
    "    # The template to use\n",
    "    template: str\n",
    "    # The list of tools available\n",
    "    tools: List[Tool]\n",
    "    \n",
    "    def format(self, **kwargs) -> str:\n",
    "        # Get the intermediate steps (AgentAction, Observation tuples)\n",
    "        # Format them in a particular way\n",
    "        intermediate_steps = kwargs.pop(\"intermediate_steps\")\n",
    "        thoughts = \"\"\n",
    "        for action, observation in intermediate_steps:\n",
    "            thoughts += action.log\n",
    "            thoughts += f\"\\nObservation: {observation}\\nThought: \"\n",
    "        # Set the agent_scratchpad variable to that value\n",
    "        kwargs[\"agent_scratchpad\"] = thoughts\n",
    "        # Create a tools variable from the list of tools provided\n",
    "        kwargs[\"tools\"] = \"\\n\".join([f\"{tool.name}: {tool.description}\" for tool in self.tools])\n",
    "        # Create a list of tool names for the tools provided\n",
    "        kwargs[\"tool_names\"] = \", \".join([tool.name for tool in self.tools])\n",
    "        return self.template.format(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c20106-45b4-44fe-8447-d256fe29e971",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomOutputParser(AgentOutputParser):\n",
    "    \n",
    "    def parse(self, llm_output: str) -> Union[AgentAction, AgentFinish]:\n",
    "        # Check if agent should finish\n",
    "        if \"Final Answer:\" in llm_output:\n",
    "            return AgentFinish(\n",
    "                # Return values is generally always a dictionary with a single `output` key\n",
    "                # It is not recommended to try anything else at the moment :)\n",
    "                return_values={\"output\": llm_output.split(\"Final Answer:\")[-1].strip()},\n",
    "                log=llm_output,\n",
    "            )\n",
    "        # Parse out the action and action input\n",
    "        regex = r\"Action\\s*\\d*\\s*:(.*?)\\nAction\\s*\\d*\\s*Input\\s*\\d*\\s*:[\\s]*(.*)\"\n",
    "        match = re.search(regex, llm_output, re.DOTALL)\n",
    "        if not match:\n",
    "            raise ValueError(f\"Could not parse LLM output: `{llm_output}`\")\n",
    "        action = match.group(1).strip()\n",
    "        action_input = match.group(2)\n",
    "        # Return the action and action input\n",
    "        return AgentAction(tool=action, tool_input=action_input.strip(\" \").strip('\"'), log=llm_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d11a23-04c0-4548-abb8-96734478ae76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = CustomPromptTemplate(\n",
    "    template=template,\n",
    "    tools=tools,\n",
    "    # This omits the `agent_scratchpad`, `tools`, and `tool_names` variables because those are generated dynamically\n",
    "    # This includes the `intermediate_steps` variable because that is needed\n",
    "    input_variables=[\"input\", \"intermediate_steps\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf52d453-c89d-4184-80cd-7368e0c71fc5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# LLM chain consisting of the LLM and a prompt\n",
    "llm_chain = LLMChain(llm=llm_openai, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84194ca5-835c-4e93-81bd-dfd1eebdda5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_parser = CustomOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fec8ddf-50eb-4634-b27f-364af4b77330",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tool_names = [tool.name for tool in tools]\n",
    "agent = LLMSingleActionAgent(\n",
    "    llm_chain=llm_chain, \n",
    "    output_parser=output_parser,\n",
    "    stop=[\"\\nObservation:\"], \n",
    "    allowed_tools=tool_names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfe1761-0d18-4143-b566-32df13e542c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "agent_executor = AgentExecutor.from_agent_and_tools(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d4ffac-eeec-4a55-9d9b-022e1ebd7a62",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "agent_executor.run(\"How many people live in canada as of 2023?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05c840a-3435-41ef-97fe-04012a907f1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5375197-90a9-4dc6-a167-c070b105d018",
   "metadata": {},
   "source": [
    "## Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d094a7b0-6caa-4072-b369-abe73a5e32f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyMuPDFLoader\n",
    "from langchain.document_loaders import DirectoryLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06865585-1961-45b6-8919-ae68cbaf391d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "root_dir = \"pdfs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2bb863c-943b-4749-8dc8-bbe8faebf8b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# For Single PDF Loader\n",
    "# loader = pyMuPDFLoader(\"{pdf_file.pdf}\")\n",
    "loader = DirectoryLoader(f'{root_dir}/', glob=\"./*.pdf\", loader_cls=PyMuPDFLoader)\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db4b4657-0e83-4a3c-b160-32828164901e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e7185ff-a042-4226-8239-fccced8cbf26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.schema import Document\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc376a8-7ccd-4de1-aaab-13aafa15c9cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from langchain.indexes import VectorstoreIndexCreator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a6dc4e2-eec3-4fe4-8516-2791e909d023",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b885863b-2ae6-447d-ae6d-d7e8c1c09678",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=MAX_LEN, \n",
    "    chunk_overlap=0\n",
    ")\n",
    "\n",
    "texts = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "63593fd1-4bf3-4372-b6a1-4db609c3050a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "37c7760b-d86f-4cc3-be8f-7cde65046511",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import faiss\n",
    "from langchain.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869a9fee-b83d-4947-987a-6e21bfee77e3",
   "metadata": {},
   "source": [
    "## PDF with OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5b8046bc-299f-400d-b702-c6cc7fff1249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['attention_is_all_you_need.pdf', 'kg.pdf']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "pdf_folder_path = 'pdfs'\n",
    "print(os.listdir(pdf_folder_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "46f81db9-e0d4-4946-b511-13bf9bd961fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d8e7a553-9fdf-42c7-bddd-6180b080f85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFDirectoryLoader\n",
    "loader = PyPDFDirectoryLoader(pdf_folder_path)\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6950146d-232a-4df0-aa13-a9c7b0e450b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(\n",
    "    model = \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2c3e22e2-5402-4427-9dca-fc01d3a190c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader \n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "vectordb = FAISS.from_documents(docs, embedding=embeddings)\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "pdf_qa = ConversationalRetrievalChain.from_llm(OpenAI(temperature=0.8) , vectordb.as_retriever(), memory=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cffc7b80-68aa-4ff4-9291-6b456a7d20cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Attention is a mechanism used in neural networks to determine how much each input should be weighted in order to contribute to the output. It is commonly used in sequence transduction models, such as recurrent and convolutional neural networks, to connect the encoder and decoder. In the Transformer model, attention is used solely, dispensing with recurrence and convolutions.'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"what is an attention?\"\n",
    "result = pdf_qa({\"question\": query})\n",
    "print(\"Answer:\")\n",
    "result[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa42e4bb-11af-4d20-bfa8-45cb42c2b214",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1d755b-eeeb-4e57-869d-fc05ac93e49a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9149fbb6-09a7-4fc8-acdd-ecc2905b4111",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e4ea8ddd-9940-4a64-9f5d-381b88ad4c0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def store_embeddings(docs, embeddings, sotre_name, path):\n",
    "    \n",
    "    vectorStore = FAISS.from_documents(docs, embeddings)\n",
    "\n",
    "    with open(f\"{path}/faiss_{sotre_name}.pkl\", \"wb\") as f:\n",
    "        pickle.dump(vectorStore, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c86e7632-06fe-4291-a20a-0943d588f284",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_embeddings(sotre_name, path):\n",
    "    with open(f\"{path}/faiss_{sotre_name}.pkl\", \"rb\") as f:\n",
    "        VectorStore = pickle.load(f)\n",
    "    return VectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dc27aa76-8fa0-4eed-927f-61b8791d324e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Dependencies for InstructorEmbedding not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/agi/lib/python3.11/site-packages/langchain/embeddings/huggingface.py:125\u001b[0m, in \u001b[0;36mHuggingFaceInstructEmbeddings.__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mInstructorEmbedding\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m INSTRUCTOR\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient \u001b[38;5;241m=\u001b[39m INSTRUCTOR(\n\u001b[1;32m    128\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_name, cache_folder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache_folder, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_kwargs\n\u001b[1;32m    129\u001b[0m     )\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'InstructorEmbedding'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membeddings\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HuggingFaceInstructEmbeddings\n\u001b[0;32m----> 3\u001b[0m instructor_embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mHuggingFaceInstructEmbeddings\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhkunlp/instructor-xl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdevice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/agi/lib/python3.11/site-packages/langchain/embeddings/huggingface.py:131\u001b[0m, in \u001b[0;36mHuggingFaceInstructEmbeddings.__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient \u001b[38;5;241m=\u001b[39m INSTRUCTOR(\n\u001b[1;32m    128\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_name, cache_folder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache_folder, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_kwargs\n\u001b[1;32m    129\u001b[0m     )\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 131\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDependencies for InstructorEmbedding not found.\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Dependencies for InstructorEmbedding not found."
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import HuggingFaceInstructEmbeddings\n",
    "\n",
    "instructor_embeddings = HuggingFaceInstructEmbeddings(\n",
    "    model_name=\"hkunlp/instructor-xl\", \n",
    "    model_kwargs={\"device\": \"cuda\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5734ea-6964-44d4-a4cb-0e163615621d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Embedding_store_path = f\"{root_dir}/Embedding_store\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3628291f-2f97-49ad-8f82-a1ebb563877e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "db_instructEmbedd = FAISS.from_documents(texts, instructor_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f036ba-96b9-4e98-adc0-f60a15c61665",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "retriever = db_instructEmbedd.as_retriever(search_kwargs={\"k\": 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ddfe42-c3e6-45f3-ab45-87fdece6eb69",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "retriever.search_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329c3310-3846-4d74-abc1-8f97838925c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "retriever.search_kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3645a54d-85c3-47d5-95e9-cb1e3a0c7d16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "docs = retriever.get_relevant_documents(\"Who are the authors of this report?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd737d1-1937-4dec-9ca0-06732339e853",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca1406b-cf23-4858-841c-3863cddba600",
   "metadata": {},
   "source": [
    "### Testing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2558a9-2ddc-4d6e-8d88-3c94ed22d09e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ff0009-511e-42d1-af8a-924abefaeda3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Cite sources\n",
    "import textwrap\n",
    "\n",
    "def wrap_text_preserve_newlines(text, width=110):\n",
    "    # Split the input text into lines based on newline characters\n",
    "    lines = text.split('\\n')\n",
    "\n",
    "    # Wrap each line individually\n",
    "    wrapped_lines = [textwrap.fill(line, width=width) for line in lines]\n",
    "\n",
    "    # Join the wrapped lines back together using newline characters\n",
    "    wrapped_text = '\\n'.join(wrapped_lines)\n",
    "\n",
    "    return wrapped_text\n",
    "\n",
    "def process_llm_response(llm_response):\n",
    "    print(wrap_text_preserve_newlines(llm_response['result']))\n",
    "    print('\\nSources:')\n",
    "    for source in llm_response[\"source_documents\"]:\n",
    "        print(source.metadata['source'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24fcc3ed-fdc4-4479-8a15-45bc2c1db9f4",
   "metadata": {},
   "source": [
    "### Stuff Chain Type\n",
    "> A stuff chain means that all the data are used at the same time to make only one api call. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925d5d0b-9adb-4c0c-831e-a4052ed26cc0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"Use the following pieces of context to answer the question at the end. \\\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\"\"\"\n",
    "\n",
    "PROMPT = PromptTemplate(\n",
    "    template=prompt_template, input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "\n",
    "chain_type_kwargs = {\"prompt\": PROMPT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae9656d-d760-4883-8eda-960aab2b9c36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "qa_chain_instrucEmbed = RetrievalQA.from_chain_type(\n",
    "    llm=llm, \n",
    "    chain_type=\"stuff\", \n",
    "    retriever=retriever,\n",
    "    return_source_documents=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3636019-9b29-4580-b90e-8bc2d206cbf2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = 'What is an attention network'\n",
    "\n",
    "print('-------------------Instructor Embeddings------------------\\n')\n",
    "llm_response = qa_chain_instrucEmbed(query)\n",
    "process_llm_response(llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87ca900-6194-4ff2-b55b-1aff2a391fa2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = 'Please summarize these documents breifly'\n",
    "\n",
    "print('-------------------Instructor Embeddings------------------\\n')\n",
    "llm_response = qa_chain_instrucEmbed(query)\n",
    "process_llm_response(llm_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428d9a30-f2c1-4b02-b16c-901766527749",
   "metadata": {},
   "source": [
    "### Map_reduce type\n",
    "> The map_reduce type is a type that for each document, an api call is made to summarize each segment. Then a final api call is to summarize all the summarys.\n",
    "This is useful when input data is large but needs to make multiple api calls in order to get the answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58160d5-fd25-4528-b49c-032080a8b525",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "qa_chain_instrucEmbed = RetrievalQA.from_chain_type(\n",
    "    llm=llm, \n",
    "    chain_type=\"map_reduce\", \n",
    "    retriever=retriever,\n",
    "    return_source_documents=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8931b4a-a500-41f2-86b8-6e6ba0e6e09e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = 'What is an attention network'\n",
    "\n",
    "print('-------------------Instructor Embeddings------------------\\n')\n",
    "llm_response = qa_chain_instrucEmbed(query)\n",
    "process_llm_response(llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad82db2f-e791-42ab-b017-1a946f56bba9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = 'Please summarize these documents briefly'\n",
    "\n",
    "print('-------------------Instructor Embeddings------------------\\n')\n",
    "llm_response = qa_chain_instrucEmbed(query)\n",
    "process_llm_response(llm_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0482a9e5-d0bb-45bf-9620-548f61100d1b",
   "metadata": {},
   "source": [
    "### Refine Chain\n",
    "> The refine chain is similar to the map_reduce chain, but summaries are done sequentially. The summary of the first document will be an input to the second document, then the summary of the second document is generated. This proccess is repeat until the end of the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6042d3-ee92-41f2-8215-53ec2622bc0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "qa_chain_instrucEmbed = RetrievalQA.from_chain_type(\n",
    "    llm=llm, \n",
    "    chain_type=\"refine\", \n",
    "    retriever=retriever,\n",
    "    return_source_documents=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bc523d-2c39-4477-918d-e621b47cb6c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = 'What is an attention network'\n",
    "\n",
    "print('-------------------Instructor Embeddings------------------\\n')\n",
    "llm_response = qa_chain_instrucEmbed(query)\n",
    "process_llm_response(llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6411a38-7174-4ade-9d97-92a237429667",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = 'Please summarize these documents briefly'\n",
    "\n",
    "print('-------------------Instructor Embeddings------------------\\n')\n",
    "llm_response = qa_chain_instrucEmbed(query)\n",
    "process_llm_response(llm_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaad90ee-f227-4e40-b4c3-2dd33ef2c076",
   "metadata": {},
   "source": [
    "## Split Texts using LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578b1b87-886e-42d7-a1e3-01a35f935ca5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "type(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9cf6a5-be10-4a34-8da4-3a76efd3b176",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf80e15-348a-4926-ba60-baaa5228a131",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "texts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a42936-12ab-474a-bd2c-19e4e9497031",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "db_instructEmbedd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb9c91b-b7b2-4ab2-88b8-848bbf1c3f44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.chains.question_answering import load_qa_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6011c9-1971-4645-981a-b461b6c4ea09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"Given the following content, how would you split the content into two seperate parts.\n",
    "{context}\n",
    "\n",
    "Answer using the following format:\n",
    "\n",
    "Part 1:\n",
    "Part 2:\"\"\"\n",
    "PROMPT = PromptTemplate(\n",
    "    template=prompt_template, input_variables=[\"context\"]\n",
    ")\n",
    "\n",
    "chain = load_qa_chain(\n",
    "    llm,\n",
    "    chain_type=\"stuff\",\n",
    "    prompt=PROMPT\n",
    ")\n",
    "\n",
    "chain({\"input_documents\": [texts[10]]}, return_only_outputs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0b9cf6-1fc9-4430-aa19-c9337c2fe313",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "texts[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40bf9fde-50a6-4b09-96b3-7159829749fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm(\"how do you make money in the stock market\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac7b5ce-8187-4d40-8a96-82abf462eece",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agi",
   "language": "python",
   "name": "agi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
